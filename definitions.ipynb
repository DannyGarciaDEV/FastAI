{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fastai is a deep learning library built on top of PyTorch, designed to simplify training neural networks. Here are some key vocabulary terms related to fastai:\n",
    "    \n",
    "\n",
    "1.Learner: Central class in fastai that wraps the model, data, and training loop, providing methods for fitting, predicting, and evaluating models.\n",
    "\n",
    "2.DataBlock: A flexible and customizable way to define data processing pipelines, including splitting data, transforming inputs, and creating data loaders.\n",
    "\n",
    "3.DataLoader: Object that loads data in batches, often used for training and validation. Fastai provides optimized DataLoader classes for different types of data.\n",
    "\n",
    "4.Callback: Functions that modify the behavior of the training loop. Fastai has built-in callbacks for early stopping, learning rate scheduling, and more, and users can create custom callbacks.\n",
    "\n",
    "5.Fit One Cycle: A training technique that adjusts the learning rate during training, gradually increasing it to a peak and then decreasing it. This often helps models converge faster.\n",
    "\n",
    "6.Transform: Operations applied to data (like normalization, augmentation) to prepare it for training. Fastai includes many pre-defined transforms and allows custom ones.\n",
    "\n",
    "7.Metrics: Functions used to evaluate model performance during training. Fastai provides various metrics like accuracy, precision, and more.\n",
    "\n",
    "8.Transfer Learning: The practice of using a pre-trained model on a new task. Fastai simplifies applying transfer learning with its Learner class.\n",
    "\n",
    "10.One-Hot Encoding: A method to represent categorical data as binary vectors. Fastai automates this for categorical variables in datasets.\n",
    "\n",
    "11.Mixed Precision Training: A technique that speeds up training by using 16-bit floating-point numbers instead of the standard 32-bit. Fastai supports mixed precision training with minimal code changes.\n",
    "\n",
    "\n",
    "12.ItemList: Represents a collection of data items. Fastai uses it to build datasets and manage items, labels, and processing pipelines.\n",
    "\n",
    "13.Batch: A subset of data processed together during each iteration of training. Fastaiâ€™s DataLoader automatically creates batches from your data.\n",
    "\n",
    "14.Fit: The process of training the model on the dataset. In fastai, the fit method initiates the training process for a specified number of epochs.\n",
    "\n",
    "15.Epoch: One complete pass through the entire dataset during training. Fastai tracks performance metrics for each epoch.\n",
    "\n",
    "16.Validation Set: A subset of the data used to evaluate model performance during training, helping to monitor overfitting.\n",
    "\n",
    "17.Cross Entropy Loss: A common loss function used for classification tasks, especially in multi-class problems. Fastai uses this by default for many classification tasks.\n",
    "\n",
    "18.Dropout: A regularization technique to prevent overfitting by randomly setting a fraction of input units to zero during training. Fastai integrates dropout layers into its models.\n",
    "\n",
    "19.Unfreezing: The process of allowing all layers in a pre-trained model to be trained. Fastai allows freezing/unfreezing specific layers for fine-tuning.\n",
    "\n",
    "20.Discriminative Learning Rates: A technique where different layers of the model are trained with different learning rates. Fastai makes it easy to implement this for fine-tuning pre-trained models.\n",
    "\n",
    "21.SGD with Restarts: A variation of Stochastic Gradient Descent where the learning rate is periodically reset to a higher value. Fastai includes support for this optimization strategy.\n",
    "\n",
    "22.Data Augmentation: Techniques used to artificially expand the size of a dataset by creating modified versions of images or text. Fastai provides built-in functions for augmentations like rotations, flips, and color changes.\n",
    "\n",
    "Activation Function: A function applied to the output of each neuron in a neural network layer, introducing non-linearity. Common activation functions like ReLU, Sigmoid, and Softmax are supported in fastai.\n",
    "23.\n",
    "24.ConvNet (Convolutional Neural Network): A class of deep neural networks, primarily used for analyzing visual imagery. Fastai simplifies building and training ConvNets.\n",
    "\n",
    "25.ResNet: A popular type of deep neural network architecture that includes residual connections, making it easier to train very deep networks. Fastai provides pre-trained ResNet models for transfer learning.\n",
    "\n",
    "26.LR Finder (Learning Rate Finder): A technique to automatically find the optimal learning rate by gradually increasing it and observing the loss. Fastai includes an easy-to-use LR Finder method.\n",
    "\n",
    "27.Encoder: Part of the model responsible for converting input data into a hidden representation. In fastai, this is often used in models dealing with sequential data like text.\n",
    "\n",
    "28.Decoder: The counterpart to the encoder, responsible for converting hidden representations back into the desired output format. Fastai uses decoders in tasks like text generation or image segmentation.\n",
    "\n",
    "29.U-Net: A type of convolutional network architecture designed for image segmentation. Fastai has built-in support for creating U-Net models.\n",
    "\n",
    "30.Tabular Data: Data stored in table form, often used in machine learning for structured data tasks. Fastai provides tools to work with tabular data, including preprocessing, embedding layers, and model creation.\n",
    "\n",
    "31.Embedding: A representation of categorical variables as continuous vectors in a lower-dimensional space. Fastai automatically creates embeddings for categorical data in tasks like tabular data processing.\n",
    "\n",
    "32.Grad-CAM: A technique for visualizing where a neural network focuses its attention in an image. Fastai includes methods for generating Grad-CAM visualizations.\n",
    "\n",
    "33.Tokenization: The process of converting text into a sequence of tokens (words, subwords, or characters) that a model can process. Fastai provides utilities for tokenizing text data.\n",
    "\n",
    "34.Transfer Learning: Using a pre-trained model on a new but related task. Fastai makes it easy to apply transfer learning with a simple interface.\n",
    "\n",
    "35.Multi-Label Classification: A classification task where each instance can belong to multiple classes simultaneously. Fastai supports multi-label classification out of the box.\n",
    "\n",
    "36.Frozen Layers: Layers in a neural network that are not updated during training. In fastai, you can freeze and unfreeze layers to control which parts of the model are trainable.\n",
    "\n",
    "37.Fine-Tuning: The process of starting with a pre-trained model and then training it on a new task with a smaller learning rate. Fastai provides simple methods to fine-tune models.\n",
    "\n",
    "38.Momentum: A technique in optimization that helps accelerate the gradient vectors in the right directions, leading to faster converging. Fastai includes momentum in its optimization algorithms.\n",
    "\n",
    "39.TTA (Test Time Augmentation): A method of averaging predictions over multiple augmented versions of the test data, leading to more robust predictions. Fastai includes easy support for TTA.\n",
    "\n",
    "40.BatchNorm (Batch Normalization): A technique to normalize the input layer by adjusting and scaling the activations, speeding up training and improving stability. Fastai integrates BatchNorm layers automatically in many models.\n",
    "\n",
    "41.RNN (Recurrent Neural Network): A type of neural network architecture that is particularly effective for sequential data, like text or time series. Fastai provides utilities for working with RNNs.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
